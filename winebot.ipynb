{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Extract and Preprocess Text from PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Company\\ComputerHub\\wbot\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import json\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Load and preprocess the corpus\n",
    "pdf_path = r'Corpus.pdf'\n",
    "corpus_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Split corpus into meaningful chunks\n",
    "corpus_chunks = corpus_text.split('\\n\\n')  # Split based on paragraphs or other delimiters\n",
    "\n",
    "# Load SentenceTransformer model for embedding\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "corpus_embeddings = model.encode(corpus_chunks, convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Load the Q&A Data from saq.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Q&A data from JSON file\n",
    "with open(r'SAQ.json', 'r') as f:\n",
    "    saq_data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Implement the Chatbot with Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import openai\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import json\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "# Load and preprocess the corpus\n",
    "pdf_path = r'Corpus.pdf'\n",
    "corpus_text = extract_text_from_pdf(pdf_path)\n",
    "corpus_chunks = corpus_text.split('\\n\\n')  # Split based on paragraphs or other delimiters\n",
    "\n",
    "# Load SentenceTransformer model and precompute embeddings\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "corpus_embeddings = model.encode(corpus_chunks, convert_to_tensor=True)\n",
    "\n",
    "# Load Q&A data from JSON file\n",
    "with open(r'SAQ.json', 'r') as f:\n",
    "    saq_data = json.load(f)\n",
    "\n",
    "# Set OpenAI API key\n",
    "openai.api_key = 'your-api-key'\n",
    "\n",
    "# Initialize session state and cache\n",
    "if 'history' not in st.session_state:\n",
    "    st.session_state['history'] = []\n",
    "if 'cache' not in st.session_state:\n",
    "    st.session_state['cache'] = {}\n",
    "\n",
    "# Function to retrieve the most relevant answer from the corpus\n",
    "def retrieve_answer(question):\n",
    "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
    "    cos_scores = util.pytorch_cos_sim(question_embedding, corpus_embeddings)[0]\n",
    "    top_result = torch.topk(cos_scores, k=1)\n",
    "    return corpus_chunks[top_result[1].item()]\n",
    "\n",
    "# Function to generate response\n",
    "def generate_response(question):\n",
    "    # Check cache first\n",
    "    if question in st.session_state['cache']:\n",
    "        return st.session_state['cache'][question]\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "        engine=\"gpt-4\",\n",
    "        prompt=question,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    answer = response.choices[0].text.strip()\n",
    "    \n",
    "    # Cache the response\n",
    "    st.session_state['cache'][question] = answer\n",
    "    return answer\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Wine Business Chatbot\")\n",
    "st.write(\"Ask me anything about our wines!\")\n",
    "\n",
    "user_input = st.text_input(\"You: \")\n",
    "\n",
    "if user_input:\n",
    "    st.session_state['history'].append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Check if the question matches any in the sample Q&A\n",
    "    saq_answer = next((item['answer'] for item in saq_data if item['question'].lower() in user_input.lower()), None)\n",
    "    \n",
    "    if saq_answer:\n",
    "        answer = saq_answer\n",
    "    else:\n",
    "        retrieved_answer = retrieve_answer(user_input)\n",
    "        if retrieved_answer:\n",
    "            answer = generate_response(retrieved_answer)\n",
    "        else:\n",
    "            answer = \"Please contact the business directly for this information.\"\n",
    "    \n",
    "    st.session_state['history'].append({\"role\": \"bot\", \"content\": answer})\n",
    "    for msg in st.session_state['history']:\n",
    "        st.write(f\"{msg['role']}: {msg['content']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 1) (1237628973.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[8], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    \"answer\": \"Jessup Cellars has a casual and inviting atmosphere and was the first tasting room opened in Yountville in 2003.\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 1)\n"
     ]
    }
   ],
   "source": [
    "\"answer\": \"Jessup Cellars has a casual and inviting atmosphere and was the first tasting room opened in Yountville in 2003. \n",
    "You have the option of sitting inside our stunning art gallery or you may choose to enjoy the patio with giant umbrellas.\n",
    "We also have space available for private groups and special accomodations and snacks for your children. \n",
    "Our fine art is meticulously curated by our lead artist Jermaine Dante who exhibits his colorful creations in large formats in our spacious gallery where you can take in,\n",
    "or take home the inspiring art while imbibing your favorite Jessup wines.\"\n",
    "    },"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
